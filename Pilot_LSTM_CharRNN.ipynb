{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.060842Z",
     "start_time": "2019-05-14T23:57:20.053165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('./shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.077596Z",
     "start_time": "2019-05-14T23:57:20.064808Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to one-hot tensor.\n",
    "def seq_to_onehot(seq):\n",
    "    tensor = torch.zeros(len(seq[0]), batch_size, n_chars) \n",
    "    for i in range(batch_size):\n",
    "        for t, char in enumerate(seq[i]):\n",
    "            index = all_chars.index(char)\n",
    "            tensor[t][i][index] = 1\n",
    "    return tensor\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq[0]), batch_size)\n",
    "    for i in range(batch_size):\n",
    "        for t, char in enumerate(seq[i]):\n",
    "            tensor[t][i] = all_chars.index(char)\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seqs   = [get_random_seq() for _ in range(batch_size)]\n",
    "    input = seq_to_onehot([seq[:-1] for seq in seqs])\n",
    "    target = seq_to_index([seq[1:] for seq in seqs]).long()\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:22.437344Z",
     "start_time": "2019-05-14T23:57:20.131573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2315700"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Initialization.\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size  = n_chars   # Input size: Number of unique chars.\n",
    "        self.hidden_size = 700       # Hidden size: 100.\n",
    "        self.output_size = n_chars   # Output size: Number of unique chars.\n",
    "        self.num_layers = 1\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        #self.rnn_cell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers)#, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        # input shape is 128, 64, 100\n",
    "        out, (hn, cn) = self.lstm(input, hidden)\n",
    "        out = out.transpose(0, 1)\n",
    "        output = self.linear(out)\n",
    "        output = output.transpose(0, 1)\n",
    "        # output = (seq length, batch size, output size)\n",
    "        return output, (hn, cn)\n",
    "        # in: L, N, H(in)\n",
    "        # in: (h_0, c_0) = (num_layers, N, H(out)), (num_layers, N, H(cell))\n",
    "        # out: length, batch size, hidden size * (1)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initial hidden state.\n",
    "        # 1 means batch size = 1.\n",
    "        h0 = torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        return (h0, c0)\n",
    "\n",
    "    \n",
    "netOG = Net()     # Create the network instance.\n",
    "netOG.to(device)  # Move the network parameters to the specified device.\n",
    "sum(p.numel() for p in netOG.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Step and Evaluation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:22.449539Z",
     "start_time": "2019-05-14T23:57:22.440333Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_step(net, opt, input, target):\n",
    "    # Initialize hidden state and gradients.\n",
    "    hidden = net.init_hidden()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # Forward pass.\n",
    "    output, hidden = net(input, hidden)\n",
    "    \n",
    "    # Compute loss. Flatten output and target tensors and compute cross-entropy.\n",
    "    #print()\n",
    "    #print(output.shape, target.shape)\n",
    "    loss = loss_func(output.reshape(-1, net.output_size), target.reshape(-1))\n",
    "\n",
    "    # Backward pass and optimization.\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation step function.\n",
    "def eval_step(net, init_seq='W', predicted_len=100):\n",
    "    net.eval()\n",
    "    \n",
    "    # Initialize the hidden state, input and the predicted sequence.\n",
    "    hidden        = net.init_hidden()\n",
    "    init_input    = seq_to_onehot([init_seq]*net.batch_size).to(device)\n",
    "    predicted_seq = init_seq\n",
    "\n",
    "    # Use initial string to \"build up\" hidden state.\n",
    "    for t in range(len(init_seq) - 1):\n",
    "        # network wants seq_length, batch_size, n_chars\n",
    "        output, hidden = net(init_input[t].unsqueeze(0), hidden)  # Reshape input to (1, batch_size, -1).\n",
    "        \n",
    "    # Set current input as the last character of the initial string.\n",
    "    input = init_input[-1,:,:].unsqueeze(0)  # Reshape input to (1, batch_size, -1).\n",
    "    \n",
    "    # Predict more characters after the initial string.\n",
    "    for t in range(predicted_len):\n",
    "        # Get the current output and hidden state.\n",
    "        output, hidden = net(input, hidden)\n",
    "        \n",
    "        # Sample from the output as a multinomial distribution.\n",
    "        predicted_index = torch.multinomial(output[0, 0, :].exp(), 1)[0]\n",
    "\n",
    "        \n",
    "        # Add predicted character to the sequence and use it as next input.\n",
    "        predicted_char  = all_chars[predicted_index]\n",
    "        predicted_seq  += predicted_char\n",
    "\n",
    "        \n",
    "        # Use the predicted character to generate the input of next round.\n",
    "        #input = seq_to_onehot(predicted_char).to(device)\n",
    "        #input = input.unsqueeze(0).unsqueeze(0)  # Reshape input to (1, batch_size, -1).\n",
    "        input = seq_to_onehot([predicted_char]*net.batch_size).to(device)\n",
    "        input = input[0,:,:].unsqueeze(0)  # Reshape input to (1, batch_size, -1).\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    return predicted_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.556497Z",
     "start_time": "2019-05-14T23:57:22.478732Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of iterations.\n",
    "# NOTE: You may reduce the number of training iterations if the training takes long.\n",
    "iters       = 10000  # Number of training iterations.\n",
    "print_iters = 100    # Number of iterations for each log printing.\n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.Adam(netOG.parameters(), lr=0.005)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "start_train = timeit.default_timer()\n",
    "\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    #print(target.shape)\n",
    "    #print()\n",
    "    # input shape is 128, 64, 100\n",
    "    # target shape is 128, 64\n",
    "    # output shape is 128, 64, 100\n",
    "    loss      = train_step(netOG, opt, input, target)   # Calculate the loss.\n",
    "    loss_sum += loss                                  # Accumulate the loss.\n",
    "\n",
    "    #print(i)\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(eval_step(netOG)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0\n",
    "\n",
    "end_train = timeit.default_timer()\n",
    "print (\"Training time elapsed:\", end_train - start_train, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(netOG.state_dict(), 'VanillaRNN_params_ -layers  -700.pth')\n",
    "\n",
    "### with 3 layers, hidden 500, train time was 1662s, final loss was 2.290\n",
    "### with 3 layers, hidden 300, train time was 1534s, final loss was 0.741\n",
    "# with 3 layers, hidden 200, train time was 1440s, final loss was 1.160\n",
    "# with 3 layers, hidden 100, train time was 1287s, final loss was 1.376\n",
    "\n",
    "### with 2 layers, hidden 700, train time was 1714s, final loss was 0.740\n",
    "### with 2 layers, hidden 500, train time was 1612s, final loss was 0.794\n",
    "# with 2 layers, hidden 300, train time was 1393s, final loss was 0.856\n",
    "# with 2 layers, hidden 200, train time was 1256, final loss was 1.107\n",
    "# with 2 layers, hidden 100, train time was 1256s, final loss was 1.324\n",
    "\n",
    "### with 1 layers, hidden 700, train time was 2321s, final loss was 0.797\n",
    "# with 1 layers, hidden 500, train time was 1547s, final loss was 0.928\n",
    "\n",
    "\n",
    "# 1 layer?\n",
    "# hidden 200? hidden 700?\n",
    "# new batch size?\n",
    "# more randomness in training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('VanillaRNN_lossList_ -layers h- _ .pkl', 'wb') as file:\n",
    "#     pickle.dump(all_losses, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot([loss for loss in all_losses])\n",
    "#.item()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netOG.load_state_dict(torch.load('VanillaRNN_params_1-layers h-700.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With all my heart for a kinsman follow.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "And have the lusty service and no bight,\n",
      "To use the best end itself ring for me\n",
      "To speak to the blind of the wind word Hastings\n",
      "That that no beastly swope the imach of York\n",
      "Ulusugn their loves; and now, that this took him by\n",
      "sal than this man th\n"
     ]
    }
   ],
   "source": [
    "print(eval_step(netOG, init_seq='W', predicted_len=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warwick was too sudden on the field,\n",
      "The night is all as of that feasting wrench\n",
      "Hath won to hear of Naples? woe, the gods?\n",
      "What holy time the law of troops doth make speech,\n",
      "That think upon the maid you were a grand:\n",
      "Whater hast thou, or where id you? Hast thou advised\n",
      "Thine calm this while to'll prophet o'er his honour:\n",
      "Good goodness are not fair, and he are but tent.\n",
      "Stay, I pray, sir,--gend me alone, but thou\n",
      "shalt not piece me in request,\n",
      "I doubt not buzz the plainest way: faction!'\n",
      "Blasting\n"
     ]
    }
   ],
   "source": [
    "print(eval_step(netOG, init_seq='W', predicted_len=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We shall be no more inme: who, by the yannes\n",
      "That Romeo must be leave till now deliver'd\n",
      "Friar welcomed, or madam with him\n",
      "And we do bud the wanton all understand.\n",
      "Come, that envious through the dignity than my knight.\n",
      "\n",
      "ROMEO:\n",
      "And bire your conditions!\n",
      "\n",
      "CAMILLO:\n",
      "Shy hard;\n",
      "His other this, is it for a kinst mother\n",
      "To be three shrew-back than thou hast; this self-will ill.\n",
      "\n",
      "AUTOLYCUS:\n",
      "When fare, sir, I come to the feat of the air,--for chresion\n",
      "I now drink to-morrow, come from them, and reason\n",
      "In cold corse a Roman, that any botty on\n",
      "me to do remove:\n",
      "Opp gone! Now foretel some saint illess your children's son\n",
      "And three or four and as lift as high blood,\n",
      "The lininess will not have put your noble\n",
      "That seest a piece of door and honour now,\n",
      "In brief with that dreams, and all in Ravenspurgh,\n",
      "That instance to this thing you gle tears to take\n",
      "no more than a youngerier, makes thee what a chantelioy movest.\n",
      "\n",
      "VIRGILIA:\n",
      "Sir, do you hear?\n",
      "\n",
      "Second Citizen:\n",
      "No, no soverejeal: the rest of those jealousie\n"
     ]
    }
   ],
   "source": [
    "print(eval_step(netOG, init_seq='W', predicted_len=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2-layers, h-500\n",
    "# Why have you raised?\n",
    "\n",
    "# LEONTES:\n",
    "# Thou hast broke for revenge and all,\n",
    "# You promised wept in happy days,\n",
    "# As our be not permity's a prophecy\n",
    "# Doth shame to take some though gallows from the air\n",
    "# And bring it with a fury to report him.\n",
    "\n",
    "# LARTIUS:\n",
    "# These dieds and truth to flame as scarlet's reporter.\n",
    "\n",
    "# Officer:\n",
    "# You may shall posize.\n",
    "\n",
    "# LEONTES:\n",
    "# What news, preposterous craft\n",
    "# To found this Perditaon: hook, wouldst not spool,\n",
    "# Under your charity to the house of Knebl.\n",
    "# I come to hence with other in thy beads!\n",
    "# For she's my squife rivers from my banishment.\n",
    "\n",
    "# QUEEN ELIZABETH:\n",
    "# Tut, tumper; what of that?\n",
    "# You are retired, I would this put in stone:\n",
    "# The world vouchs of stud of death must have them.\n",
    "\n",
    "# TRANIO:\n",
    "# Sir, look sweet, 'tis the fine a tyrant for Henry's\n",
    "# apposition. We are you, repair of court? bootless labour\n",
    "# Will have you both by honour shall be so:\n",
    "# I have a daughter where youtht of hide herself\n",
    "# What doth he be an arch-reding-back, the Moltag!\n",
    "\n",
    "# DORSET:\n",
    "# This wish, my tears are stop amorous farm\n",
    "# And with all her play'd that monstrous room,\n",
    "# Some virtuous syralt ought to the drowsing brood;\n",
    "# Who is't being such fal as last of informon.\n",
    "\n",
    "# Second Gentleman:\n",
    "# How now, sir! Away son will not work out?\n",
    "# For we arriven, which to do it.\n",
    "\n",
    "# GRUMIO:\n",
    "# Therefore lend this deed. Excover is here and mine,\n",
    "# Put up in scarling admiring, yet with spicitude,\n",
    "# Expede the proclamation: on our encouragement\n",
    "# Leaving argus he under his battle stoop\n",
    "# A word with joyful in his fall on us:\n",
    "# Come, go with us; like one safety for our priest\n",
    "# How merity shall be what lay had shorter\n",
    "# Renonned in the chiver men are possection\n",
    "# That no man enter in this presence of their ears:\n",
    "# Doose shore recount him will she never sing is very\n",
    "# That shots in silver dregs of such a price.\n",
    "\n",
    "# PAULINA:\n",
    "# None, mother, I hear, Juliet, be not report;\n",
    "# Lucentio met! make me with thee women.\n",
    "\n",
    "# MERCUTIO:\n",
    "# Be thore: betwixt of love!\n",
    "\n",
    "# DUCHESS OF YORK:\n",
    "# This is the urbike of him.\n",
    "\n",
    "# A Patrician:\n",
    "# Nay, doth he do wear by him, for he that mightst\n",
    "# me still would tell who firs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
